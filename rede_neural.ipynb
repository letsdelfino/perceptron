{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "[0.50487227332410989]\n",
      "[0.5040141081036229]\n",
      "[0.49622826691646965]\n",
      "[0.49552090094447721]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Created on April 12th 2017\n",
    "    Updated on April 20th 2019 \n",
    "    \n",
    "    A simple and didactic one hidden Multilayer Perceptron\n",
    "    \n",
    "    @author: Altino Dantas\n",
    "'''\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "from random import random\n",
    "\n",
    "def PMC(inputs, outputs, W1NumberOfNeurons, W2NumberOfNeurons, alpha, epsilon, max_it, loss_path='dados.dat'):\n",
    "    \n",
    "    '''\n",
    "       ############# Initialize vars #############\n",
    "    '''\n",
    "    \n",
    "    times = 1\n",
    "    \n",
    "    W2, W2Aux, W1 = [],[],[]\n",
    "\n",
    "    # neuron j weight i, thus, they will seen W = [[0.35, 0.15, 0.2], [0.35, 0.25, 0.3]]\n",
    "    \n",
    "    # set random W1 weights // bias is the first weight in each neuron;\n",
    "    for neuron in range(W1NumberOfNeurons):\n",
    "        W1.append([])\n",
    "        # the number of weights for each neuron in W1 is the number of features in the sample\n",
    "        for weight in range(len(inputs[0])):\n",
    "            W1[neuron].append(random())\n",
    "\n",
    "    # set random W2 weights // bias is the first weight in each neuron; \n",
    "    for neuron in range(W2NumberOfNeurons):\n",
    "        W2.append([])\n",
    "        # num of weights linked with each W2 neuron is the num of outs from Layer 1 plus one (regarding to bias)\n",
    "        for weight in range(len(W1) + 1): \n",
    "            W2[neuron].append(random())       \n",
    "\n",
    "    # activation power u\n",
    "    U1 = [0 for x in range(W1NumberOfNeurons)]\n",
    "    U2 = [0 for x in range(W2NumberOfNeurons)]\n",
    "\n",
    "    # output produced by g(u)\n",
    "    Y1 = [0 for x in range(W1NumberOfNeurons)] \n",
    "    Y2 = [0 for x in range(W2NumberOfNeurons)]\n",
    "    \n",
    "    # Instrumentation to save loss in a external file\n",
    "    outTXT = open(loss_path, 'w')\n",
    "    textLines = []\n",
    "\n",
    "    '''\n",
    "       ############# Training loop #############\n",
    "    '''\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        iniErro = ETotal(W1,W2,U1,U2,Y1,Y2,inputs,outputs)\n",
    "\n",
    "        '''\n",
    "            ############# iterate over each sample #############\n",
    "        '''\n",
    "        \n",
    "        for i in range(len(inputs)):\n",
    "            \n",
    "            '''\n",
    "                ############# propagation step #############\n",
    "            '''\n",
    "            \n",
    "            U1 = updateU1(inputs[i],U1, W1)\n",
    "            Y1 = updateY1(U1,Y1)\n",
    "            U2 = updateU2(Y1,U2,W2)\n",
    "            Y2 = updateY2(U2, Y2)       \n",
    "\n",
    "            '''\n",
    "                ############# backpropagation step #############\n",
    "            '''\n",
    "            W2Aux = copy.deepcopy(W2)\n",
    "            \n",
    "            # updating first level (last layer)\n",
    "            for neuron in range(len(W2)):\n",
    "                W2[neuron][0] += 1 * alpha * (outputs[i][neuron] - Y2[neuron]) * (Y2[neuron] * (1 - Y2[neuron])) #bias    \n",
    "                for weight in range(1, len(W2[neuron])):\n",
    "                    W2[neuron][weight] += Y1[weight-1] * alpha * \\\n",
    "                    (outputs[i][neuron] - Y2[neuron]) * (Y2[neuron] * (1 - Y2[neuron]))\n",
    "\n",
    "            # updating second level (first hidden layer)\n",
    "            for neuron in range(len(W1)):\n",
    "                for weight in range(len(W1[neuron])):\n",
    "                    js = .0\n",
    "                    for neuronW2 in range(len(W2Aux)):\n",
    "                        js += W2Aux[neuronW2][neuron + 1] * \\\n",
    "                        (outputs[i][neuronW2] - Y2[neuronW2]) * (Y2[neuronW2] * (1 - Y2[neuronW2]))\n",
    "                    W1[neuron][weight] += inputs[i][weight] * alpha * js * (Y1[neuron] * (1 - Y1[neuron])) \n",
    "\n",
    "        endErro = ETotal(W1,W2,U1,U2,Y1,Y2,inputs,outputs)\n",
    "\n",
    "        if (math.fabs(iniErro - endErro) < epsilon) or (times == max_it):\n",
    "            break \n",
    "        else:\n",
    "            if times % 100 == 0:\n",
    "                print('{:d}'.format(times))\n",
    "            \n",
    "            string = str(iniErro) + \"\\n\"\n",
    "            textLines.append(string)\n",
    "            times += 1\n",
    "    \n",
    "    # save loss in file\n",
    "    outTXT.writelines(textLines)\n",
    "    outTXT.close()\n",
    "    \n",
    "    return (W1,W2)\n",
    "\n",
    "def updateU1(anInput,U1,W1): \n",
    "    for neuron in range(len(W1)):\n",
    "        U1[neuron] = 0\n",
    "        for k in range(len(anInput)):\n",
    "            U1[neuron]  += anInput[k] * W1[neuron][k]  \n",
    "    return U1\n",
    "\n",
    "def updateY1(uVec, Y1): \n",
    "    for neuron in range(len(Y1)):\n",
    "        Y1[neuron] = funcao_logistica(uVec[neuron])\n",
    "    return Y1\n",
    "\n",
    "def updateU2(anInput,U2, W2): \n",
    "    for neuron in range(len(U2)):\n",
    "        U2[neuron] = W2[neuron][0] # initializing each neuron u value with bias from W2 weight \n",
    "        for weight in range(len(anInput)):\n",
    "            U2[neuron] += anInput[weight] * W2[neuron][weight + 1]\n",
    "    return U2\n",
    "            \n",
    "def updateY2(uVec,Y2): \n",
    "    for i in range(len(uVec)):\n",
    "        Y2[i]  = funcao_logistica(uVec[i])\n",
    "    return Y2\n",
    "        \n",
    "def funcao_logistica(u):\n",
    "    return 1/(1 + np.exp(-u));\n",
    "\n",
    "def ETotal(W1,W2,U1,U2,Y1,Y2,inputs,outputs):\n",
    "    average = .0    \n",
    "    for j in range( len(inputs) ):\n",
    "        U1 = updateU1(inputs[j],U1,W1)\n",
    "        Y1 = updateY1(U1,Y1)\n",
    "        U2 = updateU2(Y1, U2,W2)\n",
    "        Y2 = updateY2(U2,Y2)\n",
    "        for i in range( len( W2 ) ): # for all neurons\n",
    "            average += (math.pow(Y2[i] - outputs[j][i], 2))/len(W2)\n",
    "            \n",
    "    return ( average / len( inputs ) )\n",
    "\n",
    "def predict(sample, W1, W2):\n",
    "    \n",
    "    # activation power u\n",
    "    U1 = [0 for x in range(len(W1))]\n",
    "    U2 = [0 for x in range(len(W2))]\n",
    "\n",
    "    # output produced by g(u)\n",
    "    Y1 = [0 for x in range(len(W1))] \n",
    "    Y2 = [0 for x in range(len(W2))]\n",
    "    \n",
    "    '''\n",
    "        ############# propagation step #############\n",
    "    '''\n",
    "    \n",
    "    U1 = updateU1(sample,U1, W1)\n",
    "    Y1 = updateY1(U1,Y1)\n",
    "    U2 = updateU2(Y1,U2,W2)\n",
    "    Y2 = updateY2(U2, Y2)\n",
    "    \n",
    "    return Y2\n",
    "\n",
    "        \n",
    "def main():\n",
    "    \n",
    "    W1NumberOfNeurons = 2     \n",
    "    W2NumberOfNeurons = 1 \n",
    "\n",
    "    alpha   = 0.1\n",
    "    epsilon = .0000001\n",
    "    max_it  = 1000 \n",
    "\n",
    "    # first value in each input is the constant input for bias\n",
    "    inputs = [[1,0,0],[1,0,1],[1,1,0],[1,1,1]]\n",
    "    outputs = [[0],[1],[1],[0]]\n",
    "\n",
    "    W1, W2 = PMC(inputs=inputs, \n",
    "                 outputs=outputs, \n",
    "                 W1NumberOfNeurons=W1NumberOfNeurons, \n",
    "                 W2NumberOfNeurons=W2NumberOfNeurons, \n",
    "                 alpha=alpha,\n",
    "                 epsilon=epsilon,\n",
    "                 max_it=max_it)\n",
    "    \n",
    "    tests =[[1,0,0],\n",
    "            [1,0,1],\n",
    "            [1,1,0],\n",
    "            [1,1,1]]\n",
    "    \n",
    "    for t in tests:\n",
    "        print(predict(t,W1,W2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
